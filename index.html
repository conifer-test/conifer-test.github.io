<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />

    <!-- BEGIN Info -->
    <meta
      name="description"
      content="Conifer - An open-source open-source framework that allows developers to easily deploy an infrastructure that runs Cypress tests in parallel which reduces the total time it takes to execute a full test suite for local development."
    />
    <meta name="title" property="og:title" content="Conifer" />
    <meta property="og:type" content="Website" />
    <meta name="image" property="og:image" content="images/thumb.png" />
    <meta
      name="description"
      property="og:description"
      content="Conifer - An open-source open-source framework that allows developers to easily deploy an infrastructure that runs Cypress tests in parallel which reduces the total time it takes to execute a full test suite for local development."
    />
    <meta name="author" content="Conifer" />
    <!-- END Info -->
    <script
      defer
      data-domain="conifer-test.github.io"
      src="https://plausible.io/js/plausible.js"
    ></script>
    <!-- BEGIN favicon -->
    <link
      rel="apple-touch-icon"
      sizes="180x180"
      href="images/favicon/apple-touch-icon.png"
    />
    <link
      rel="icon"
      type="image/png"
      sizes="32x32"
      href="images/favicon/favicon-32x32.png"
    />
    <link
      rel="icon"
      type="image/png"
      sizes="16x16"
      href="images/favicon/favicon-16x16.png"
    />
    <link rel="manifest" href="images/favicon/site.webmanifest" />
    <link
      rel="mask-icon"
      href="images/favicon/safari-pinned-tab.svg"
      color="#5bbad5"
    />
    <link rel="shortcut icon" href="images/favicon/favicon.ico" />
    <meta name="msapplication-TileColor" content="#ffffff" />
    <meta
      name="msapplication-config"
      content="images/favicon/browserconfig.xml"
    />
    <meta name="theme-color" content="#ffffff" />
    <!-- END favicon -->

    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Conifer</title>

    <link
      rel="stylesheet"
      href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/all.min.css"
    />
    <link
      rel="stylesheet"
      href="https://unpkg.com/@tailwindcss/typography@0.2.x/dist/typography.min.css"
    />
    <link rel="stylesheet" href="stylesheets/reset.css" />
    <link rel="stylesheet" href="stylesheets/style.css" />
    <link rel="stylesheet" href="stylesheets/responsive.css" />
  </head>
  <body>
    <header class="mobile-menu-closed">
      <div id="header">
        <a href="/">
          <img src="images/logo/logo-name.svg" />
        </a>
        <nav>
          <a href="#start-here" class="selected">Start Here</a>
          <a href="#case-study">Case Study</a>
          <a href="#presentation">Presentation</a>
          <a href="#our-team">Our Team</a>
          <a
            href="https://github.com/conifer-test/conifer/blob/main/README.md"
            target="_blank"
            >Docs</a
          >
          <a href="https://github.com/conifer-test" target="_blank" class="icon"
            ><i class="fab fa-github"></i
          ></a>
        </nav>
        <div id="menu">
          <button type="button">
            <svg
              id="mobile-open"
              xmlns="http://www.w3.org/2000/svg"
              fill="none"
              viewBox="0 0 24 24"
              stroke="currentColor"
              aria-hidden="true"
            >
              <path
                stroke-linecap="round"
                stroke-linejoin="round"
                stroke-width="2"
                d="M4 6h16M4 12h16M4 18h16"
              />
            </svg>
            <svg
              id="mobile-close"
              xmlns="http://www.w3.org/2000/svg"
              fill="none"
              viewBox="0 0 24 24"
              stroke="currentColor"
              aria-hidden="true"
            >
              <path
                stroke-linecap="round"
                stroke-linejoin="round"
                stroke-width="2"
                d="M6 18L18 6M6 6l12 12"
              />
            </svg>
          </button>
        </div>
      </div>

      <div id="header-buffer"></div>

      <div id="mobile-menu">
        <a href="#start-here" class="selected">Start Here</a>
        <a href="#case-study">Case Study</a>
        <a href="#presentation">Presentation</a>
        <a href="#our-team">Our Team</a>
        <a
          href="https://github.com/conifer-test/conifer/blob/main/README.md"
          target="_blank"
          >Docs</a
        >
        <a href="https://github.com/conifer-test" target="_blank"
          ><i class="fab fa-github"></i> GitHub</a
        >
      </div>
    </header>

    <div id="start-here" class="main-section">
      <div class="h-full">
        <div class="static-logo-color"></div>
        <div class="bg-gray">
          <img
            class="conifer sm-screen"
            src="images/logo/conifer_white_graphic_color.png"
          />
          <img
            class="conifer lg-screen"
            src="images/logo/conifer-name-white.png"
          />

          <p class="light-text">
            An open-source open-source framework <br />that simplifies
            <span class="text-green">parallelizing</span> Cypress tests <br />on
            AWS infrastructure.
          </p>
        </div>
      </div>
      <div class="h-full">
        <div class="bg-green static-logo-white">
          <h2>Easy to Manage & Deploy</h2>
        </div>
        <div class="bg-green">
          <h2 class="sm-header">Easy to Manage & Deploy</h2>
          <p>
            Conifer abstracts away the complexity <br />
            of working with cloud infrastructure <br />
            by automating the deployment process
          </p>
          <img class="lazy" data-src="images/diagrams/conifer_init.gif" />
        </div>
      </div>
      <!-- <div class="h-full">
        <div class="bg-pink static-logo-pink-light">
          <h2>Text and Text2</h2>
        </div>
        <div class="bg-pink">
          <h2 class="sm-header">Text and Text2</h2>
          <p>
            Some other text
          </p>

          <video autoplay loop muted playsinline class="pad">
            <source
              src="images/diagrams/infrastructure-3.mp4"
              type="video/mp4"
            />
          </video>
        </div>
      </div> -->
    </div>

    <aside id="toc">
      <ul>
        <!-- Section 1 -->
        <li data-section="section-1" class="selected">
          <a href="#section-1">
            <div>
              <div class="bullet"><div></div></div>
              <p>Introduction</p>
            </div>
          </a>
        </li>
        <li data-section="section-1" class="subitem">
          <a href="#section-1-1">
            <div>
              <div class="bullet"><div></div></div>
              <p>What is Testing?</p>
            </div>
          </a>
        </li>
        <li data-section="section-1" class="subitem">
          <a href="#section-1-2">
            <div>
              <div class="bullet"><div></div></div>
              <p>The Problem</p>
            </div>
          </a>
        </li>
        <li data-section="section-1" class="subitem">
          <a href="#section-1-3">
            <div>
              <div class="bullet"><div></div></div>
              <p>How Do We Speed up Tests?</p>
            </div>
          </a>
        </li>
        <!-- Section 2 -->
        <li data-section="section-2">
          <a href="#section-2">
            <div>
              <div class="bullet"><div></div></div>
              <p>Potential Solutions</p>
            </div>
          </a>
        </li>
        <li data-section="section-2" class="subitem">
          <a href="#section-2-1">
            <div>
              <div class="bullet"><div></div></div>
              <p>Software-as-a-Service</p>
            </div>
          </a>
        </li>
        <li data-section="section-2" class="subitem">
          <a href="#section-2-2">
            <div>
              <div class="bullet"><div></div></div>
              <p>Do it Yourself</p>
            </div>
          </a>
        </li>
        <li data-section="section-2" class="subitem">
          <a href="#section-2-3">
            <div>
              <div class="bullet"><div></div></div>
              <p>Conifer</p>
            </div>
          </a>
        </li>
        <!-- Section 3 -->
        <li data-section="section-3">
          <a href="#section-3">
            <div>
              <div class="bullet"><div></div></div>
              <p>Using Conifer</p>
            </div>
          </a>
        </li>
        <li data-section="section-3" class="subitem">
          <a href="#section-3-1">
            <div>
              <div class="bullet"><div></div></div>
              <p>conifer init</p>
            </div>
          </a>
        </li>
        <li data-section="section-3" class="subitem">
          <a href="#section-3-2">
            <div>
              <div class="bullet"><div></div></div>
              <p>conifer build</p>
            </div>
          </a>
        </li>
        <li data-section="section-3" class="subitem">
          <a href="#section-3-3">
            <div>
              <div class="bullet"><div></div></div>
              <p>conifer deploy</p>
            </div>
          </a>
        </li>
        <li data-section="section-3" class="subitem">
          <a href="#section-3-4">
            <div>
              <div class="bullet"><div></div></div>
              <p>conifer run</p>
            </div>
          </a>
        </li>
        <li data-section="section-3" class="subitem">
          <a href="#section-3-5">
            <div>
              <div class="bullet"><div></div></div>
              <p>conifer teardown</p>
            </div>
          </a>
        </li>
        <!-- Section 4 -->
        <li data-section="section-4">
          <a href="#section-4">
            <div>
              <div class="bullet"><div></div></div>
              <p>Benchmarking Conifer</p>
            </div>
          </a>
        </li>
        <!-- Section 5 -->
        <li data-section="section-5">
          <a href="#section-5">
            <div>
              <div class="bullet"><div></div></div>
              <p>Algorithm</p>
            </div>
          </a>
        </li>
        <li data-section="section-5" class="subitem">
          <a href="#section-5-1">
            <div>
              <div class="bullet"><div></div></div>
              <p>Stage 1: Allocate by File Count</p>
            </div>
          </a>
        </li>
        <li data-section="section-5" class="subitem">
          <a href="#section-5-2">
            <div>
              <div class="bullet"><div></div></div>
              <p>Stage 2: Allocate by Timing Data</p>
            </div>
          </a>
        </li>
        <li data-section="section-5" class="subitem">
          <a href="#section-5-3">
            <div>
              <div class="bullet"><div></div></div>
              <p>Final Algorithm</p>
            </div>
          </a>
        </li>
        <!-- Section 6 -->
        <li data-section="section-6">
          <a href="#section-6">
            <div>
              <div class="bullet"><div></div></div>
              <p>Behind the Scenes: How Conifer Works</p>
            </div>
          </a>
        </li>
        <li data-section="section-6" class="subitem">
          <a href="#section-6-1">
            <div>
              <div class="bullet"><div></div></div>
              <p>Overview of Responsibilities</p>
            </div>
          </a>
        </li>
        <li data-section="section-6" class="subitem">
          <a href="#section-6-2">
            <div>
              <div class="bullet"><div></div></div>
              <p>Preparing Infrastructure Components</p>
            </div>
          </a>
        </li>
        <li data-section="section-6" class="subitem">
          <a href="#section-6-3">
            <div>
              <div class="bullet"><div></div></div>
              <p>Blueprint for a Single Node: Docker Image</p>
            </div>
          </a>
        </li>
        <li data-section="section-6" class="subitem">
          <a href="#section-6-4">
            <div>
              <div class="bullet"><div></div></div>
              <p>Provisioning the Infrastructure</p>
            </div>
          </a>
        </li>
        <li data-section="section-6" class="subitem">
          <a href="#section-6-5">
            <div>
              <div class="bullet"><div></div></div>
              <p>Managing the Test Orchestration Process</p>
            </div>
          </a>
        </li>
        <li data-section="section-6" class="subitem">
          <a href="#section-6-6">
            <div>
              <div class="bullet"><div></div></div>
              <p>Executing the Test Suite: Within a Single Node</p>
            </div>
          </a>
        </li>
        <li data-section="section-6" class="subitem">
          <a href="#section-6-7">
            <div>
              <div class="bullet"><div></div></div>
              <p>Persisting Test Results</p>
            </div>
          </a>
        </li>
        <li data-section="section-6" class="subitem">
          <a href="#section-6-8">
            <div>
              <div class="bullet"><div></div></div>
              <p>Communicating Test Results to the User</p>
            </div>
          </a>
        </li>
        <li data-section="section-6" class="subitem">
          <a href="#section-6-9">
            <div>
              <div class="bullet"><div></div></div>
              <p>Final Architecture</p>
            </div>
          </a>
        </li>
        <!-- Section 7 -->
        <li data-section="section-7">
          <a href="#section-7">
            <div>
              <div class="bullet"><div></div></div>
              <p>Implementation Challenges</p>
            </div>
          </a>
        </li>
        <li data-section="section-7" class="subitem">
          <a href="#section-7-1">
            <div>
              <div class="bullet"><div></div></div>
              <p>Going Serverless</p>
            </div>
          </a>
        </li>
        <li data-section="section-7" class="subitem">
          <a href="#section-7-2">
            <div>
              <div class="bullet"><div></div></div>
              <p>Sending Test Results to the User</p>
            </div>
          </a>
        </li>
        <!-- Section 8 -->
        <li data-section="section-8">
          <a href="#section-8">
            <div>
              <div class="bullet"><div></div></div>
              <p>Future Work</p>
            </div>
          </a>
        </li>
        <li data-section="section-8" class="subitem">
          <a href="#section-8-1">
            <div>
              <div class="bullet"><div></div></div>
              <p>Dynamic Allocation of Tests</p>
            </div>
          </a>
        </li>
        <li data-section="section-8" class="subitem">
          <a href="#section-8-2">
            <div>
              <div class="bullet"><div></div></div>
              <p>Additional Features</p>
            </div>
          </a>
        </li>
      </ul>
    </aside>

    <div id="case-study" class="main-section">
      <div id="case-study-content">
        <div class="prose">
          <h1>Case Study</h1>
          <!-- Section 1 -->
          <h2 id="section-1">1. Introduction</h2>

          <!-- <p>
            Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do
            eiusmod tempor incididunt ut labore et dolore magna aliqua. Gravida
            neque convallis a cras semper auctor neque vitae tempus. At auctor
            urna nunc id cursus metus aliquam. Ut tellus elementum sagittis
            vitae et leo duis. Sit amet purus gravida quis blandit turpis cursus
            in. Sollicitudin nibh sit amet commodo.
          </p>
          <ul>
            <li><strong>Strong</strong>: List item.</li>
            <li><strong>Strong</strong>: List item.</li>
            <li><strong>Strong</strong>: List item.</li>
          </ul>

          <ol>
            <li>List item.</li>
            <li>List item.</li>
            <li>List item.</li>
            <li>List item</li>
          </ol>

          <blockquote>"Sample quote”</blockquote>
          <img class="lazy" data-src="images/diagrams/example-image.png" />
          <a href="https://link/" target="_blank">link words</a> -->

          <h3 id="section-1-1">1.1 What is Testing?</h3>
          <h4 id="section-1-1-1">
            A Brief History of Testing in Software Development
          </h4>
          <p>
            Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do
            eiusmod tempor incididunt ut labore et dolore magna aliqua. Gravida
            neque convallis a cras semper auctor neque vitae tempus. At auctor
            urna nunc id cursus metus aliquam. Ut tellus elementum sagittis
            vitae et leo duis. Sit amet purus gravida quis blandit turpis cursus
            in. Sollicitudin nibh sit amet commodo.
          </p>
          <h4 id="section-1-1-1">Testing in the Modern Day</h4>
          <p>
            Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do
            eiusmod tempor incididunt ut labore et dolore magna aliqua. Gravida
            neque convallis a cras semper auctor neque vitae tempus. At auctor
            urna nunc id cursus metus aliquam. Ut tellus elementum sagittis
            vitae et leo duis. Sit amet purus gravida quis blandit turpis cursus
            in. Sollicitudin nibh sit amet commodo.
          </p>
          <h4 id="section-1-1-1">End-to-End Testing</h4>
          <p>
            Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do
            eiusmod tempor incididunt ut labore et dolore magna aliqua. Gravida
            neque convallis a cras semper auctor neque vitae tempus. At auctor
            urna nunc id cursus metus aliquam. Ut tellus elementum sagittis
            vitae et leo duis. Sit amet purus gravida quis blandit turpis cursus
            in. Sollicitudin nibh sit amet commodo.
          </p>
          <h3 id="section-1-2">1.2 The Problem</h3>
          <p>
            Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do
            eiusmod tempor incididunt ut labore et dolore magna aliqua. Gravida
            neque convallis a cras semper auctor neque vitae tempus. At auctor
            urna nunc id cursus metus aliquam. Ut tellus elementum sagittis
            vitae et leo duis. Sit amet purus gravida quis blandit turpis cursus
            in. Sollicitudin nibh sit amet commodo.
          </p>

          <h3 id="section-1-3">1.3 How Do We Speed up Tests?</h3>
          <h4 id="section-1-3-1">Parallelization</h4>
          <p>
            Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do
            eiusmod tempor incididunt ut labore et dolore magna aliqua. Gravida
            neque convallis a cras semper auctor neque vitae tempus. At auctor
            urna nunc id cursus metus aliquam. Ut tellus elementum sagittis
            vitae et leo duis. Sit amet purus gravida quis blandit turpis cursus
            in. Sollicitudin nibh sit amet commodo.
          </p>
          <h4 id="section-1-3-2">Local Parallelization</h4>
          <p>
            Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do
            eiusmod tempor incididunt ut labore et dolore magna aliqua. Gravida
            neque convallis a cras semper auctor neque vitae tempus. At auctor
            urna nunc id cursus metus aliquam. Ut tellus elementum sagittis
            vitae et leo duis. Sit amet purus gravida quis blandit turpis cursus
            in. Sollicitudin nibh sit amet commodo.
          </p>
          <h4 id="section-1-3-3">Horizontal Scaling</h4>
          <p>
            Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do
            eiusmod tempor incididunt ut labore et dolore magna aliqua. Gravida
            neque convallis a cras semper auctor neque vitae tempus. At auctor
            urna nunc id cursus metus aliquam. Ut tellus elementum sagittis
            vitae et leo duis. Sit amet purus gravida quis blandit turpis cursus
            in. Sollicitudin nibh sit amet commodo.
          </p>
          <!-- Section 2 -->
          <h2 id="section-2">2. Potential Solutions</h2>
          <h3 id="section-2-1">2.1 Software-as-a-Service</h3>
          <p>
            Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do
            eiusmod tempor incididunt ut labore et dolore magna aliqua. Gravida
            neque convallis a cras semper auctor neque vitae tempus. At auctor
            urna nunc id cursus metus aliquam. Ut tellus elementum sagittis
            vitae et leo duis. Sit amet purus gravida quis blandit turpis cursus
            in. Sollicitudin nibh sit amet commodo.
          </p>

          <h3 id="section-2-2">2.2 Do It Yourself</h3>
          <h4 id="section-2-2-1">100% DIY</h4>
          <p>
            Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do
            eiusmod tempor incididunt ut labore et dolore magna aliqua. Gravida
            neque convallis a cras semper auctor neque vitae tempus. At auctor
            urna nunc id cursus metus aliquam. Ut tellus elementum sagittis
            vitae et leo duis. Sit amet purus gravida quis blandit turpis cursus
            in. Sollicitudin nibh sit amet commodo.
          </p>
          <h4 id="section-2-2-2">DIY + Freemium</h4>
          <p>
            Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do
            eiusmod tempor incididunt ut labore et dolore magna aliqua. Gravida
            neque convallis a cras semper auctor neque vitae tempus. At auctor
            urna nunc id cursus metus aliquam. Ut tellus elementum sagittis
            vitae et leo duis. Sit amet purus gravida quis blandit turpis cursus
            in. Sollicitudin nibh sit amet commodo.
          </p>

          <h3 id="section-2-3">2.3 Conifer</h3>
          <img
            class="lazy"
            data-src="images/diagrams/potential_solutions_table.png"
            alt="table of potential solutions"
          />

          <p>
            Conifer was created for companies or developers who want a simple
            way to spin up their own infrastructure to run Cypress tests in
            parallel and fits the needs of Drone-On's team:
          </p>
          <ul>
            <li>
              <strong>Easy to set up</strong> - Conifer provides a simple CLI to
              build, deploy, and tear down AWS infrastructure while providing a
              simple live dashboard to view while their tests run in parallel.
            </li>
            <li>
              <strong>Control of infrastructure</strong> - A company like
              Drone-On will be able to maintain full control of the
              infrastructure deployed to AWS and scale up or down as they see
              fit.
            </li>
            <li>
              <strong>Pay as you go</strong> - With Conifer, Drone-On will have
              to pay for the resources they deploy to AWS, but there are no
              upfront payments. While this cost can increase depending on usage,
              it is possible to increase or decrease capacity depending on the
              user's testing demands. No upfront cost and the ability to control
              the cost based on usage make Conifer a cost-effective alternative
              for a company like Drone-On.
            </li>
          </ul>
          <p>
            The tradeoff is that Conifer is not nearly as feature-rich as a SaaS
            solution or customized DIY platform. Conifer only supports basic
            features required to test locally. It does not offer rich analytics
            nor support the range of languages and testing frameworks that a
            SaaS would.
          </p>
          <!-- Section 3 -->
          <h2 id="section-3">3. Using Conifer</h2>
          <p>
            In order to use Conifer, the user will need to have Node, npm, AWS
            CLI, and Docker installed.
          </p>
          <p>
            Install Conifer with <code>npm i -g conifer-test</code>. The
            following commands are now available:
          </p>
          <table>
            <thead>
              <tr>
                <th class="command">Command</th>
                <th>Description</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td class="command"><code>conifer init</code></td>
                <td>
                  Gathers project information, testing parameters, and
                  provisions necessary tools to build, deploy, and run conifer
                  in your application.
                </td>
              </tr>
              <tr>
                <td class="command"><code>conifer build </code></td>
                <td>
                  Builds your application with Conifer's Dockerfile and uploads
                  the image to AWS ECR.
                </td>
              </tr>
              <tr>
                <td class="command"><code>conifer deploy</code></td>
                <td>
                  Deploys the AWS infrastructure needed to run your
                  application's tests in parallel.
                </td>
              </tr>
              <tr>
                <td class="command"><code>conifer run</code></td>
                <td>
                  Runs your application's tests in parallel based on the
                  gathered testing parameters.
                </td>
              </tr>
              <tr>
                <td class="command"><code>conifer teardown</code></td>
                <td>
                  Destroys most or all of the AWS resources that were deployed.
                </td>
              </tr>
            </tbody>
          </table>

          <h3 id="section-3-1">3.1 conifer init</h3>
          <img
            class="lazy"
            data-src="images/diagrams/conifer_init.png"
            height="500px"
            alt="initialize command"
          />

          <p>
            Running the command <code>conifer init</code> will query the user
            for general information about the user's project, and the number and
            type of parallel instances to run. After the queries, Conifer will
            create a <code>.conifer</code> folder to store the deployment files,
            configuration files, and dashboard necessary to build, deploy, and
            run Conifer with the user's application.
          </p>

          <h3 id="section-3-2">3.2 conifer build</h3>
          <p>
            The <code>conifer build</code> command will utilize the user's
            project <code>Dockerfile</code> and its dependencies and connect
            Conifer's <code>Dockerfile</code> to build the consolidated image.
            Once built, the image is automatically pushed to the user's private
            AWS Elastic Container Registry (ECR).
          </p>
          <img
            class="lazy"
            data-src="images/diagrams/conifer_build.png"
            height="500px"
            alt="build command"
          />
          <p>
            Any changes made to the user's project will require a rebuild and
            re-push to ECR. However, subsequent builds and pushes are
            substantially quicker due to caching and image layers already on
            ECR.
          </p>

          <h3 id="section-3-3">3.3 conifer deploy</h3>
          <img
            class="lazy"
            data-src="images/diagrams/conifer_deploy3x.gif"
            alt="deploy command"
          />
          <p>
            The <code>conifer deploy</code> command will deploy the necessary
            resources to AWS. This command utilizes AWS Cloud Development Kit
            (CDK), a framework for defining AWS infrastructure as code and
            provisioning that infrastructure through AWS CloudFormation.
          </p>

          <h3 id="section-3-4">3.4 conifer run</h3>
          <img
            class="lazy"
            data-src="images/diagrams/conifer_run.gif"
            alt="run command"
          />
          <p>
            Once the Conifer's infrastructure has been deployed, the user can
            initiate <code>conifer run</code> to begin running the Cypress tests
            as previously configured. The local dashboard server and React
            front-end will automatically spin up and start receiving live test
            run result data for the user to view. The user will also have access
            to the videos recorded by Cypress within the dashboard.
          </p>

          <h3 id="section-3-5">3.5 conifer teardown</h3>
          <img
            class="lazy"
            data-src="images/diagrams/conifer_td4x.gif"
            alt="teardown command"
          />
          <p>
            The user can remove the Conifer infrastructure that was deployed to
            AWS using <code>conifer teardown</code>. This removes all AWS
            resources except for the image in ECR and the database unless
            otherwise specified.
          </p>
          <p>
            The user can opt to keep the current image on ECR to speed up
            subsequent image builds and pushes. DynamoDB can be kept so previous
            test run metadata can be persisted between test suite runs.
          </p>
          <p>
            At this point, you're probably wondering how much Conifer can speed
            up E2E testing. In the following section, let's examine some of the
            results one can expect when using Conifer to parallelize their
            Cypress E2E tests.
          </p>

          <!-- Section 4 -->
          <h2 id="section-4">4. Benchmarking Conifer</h2>
          <p>[TABLE]</p>
          <p>
            The above table compares the total test-run execution time for test
            suites of differing lengths with our local machine running Cypress
            versus with Conifer. Keep in mind there could be variations in a
            local test run durations depending on local machine specs; for
            reference, the device used here was a 2021 Macbook Pro (M1 Max, 32
            GB).
          </p>
          <p>These results, while impressive, also reveal two key trends:</p>
          <ol>
            <li>
              The degree to which a test run is sped up depends on the length of
              the test suite. More tests mean a more significant speed increase
              (both in absolute and relative terms).
            </li>
            <li>
              Subsequent test suite runs tend to be faster than the initial
              runs.
            </li>
          </ol>
          <p>[TABLE2]</p>
          <p>
            As shown by the run speed multipliers in the above table, the
            greater speed improvement for longer tests can be explained by the
            relatively fixed start-up time for <code>conifer run</code> A delay
            that does not apply to running tests locally. This delay takes up a
            greater proportion of the run time in the case of shorter tests, but
            since it is fixed, as the test length increases, it takes up a
            diminishing proportion of the test run duration. As you can see in
            the above table, as the test suite length progresses from small to
            large, the initial run speed multiplier progresses from 1.39x to
            3.09x, and the subsequent run speed multiplier progresses from 1.55x
            to 3.88x.
          </p>
          <p>
            Fortunately for our users, this means that the most agonizing test
            suites are the ones that get the largest boost in speed.
          </p>
          <p>
            Subsequent test suite runs tend to be faster than the initial runs
            because of Conifer's test splitting algorithm that utilizes
            meta-data from previous test runs to optimize future runs. Let's
            take a look now.
          </p>

          <!-- Section 5 -->
          <h2 id="section-5">5. Algorithm</h2>
          <p>
            Conifer allocates test files in parallel nodes using a two-stage
            algorithm.
          </p>

          <h3 id="section-5-1">5.1 Stage 1: Allocate by File Count</h3>
          <img
            class="lazy"
            data-src="images/diagrams/split_by_file_count.gif"
            alt="animation of split by file count"
          />
          <p>
            The first stage is utilized in the initial test run. During the
            initial test run, Conifer naively distributes the test files to the
            various nodes based on the total file count, such that each
            container contains roughly the same number of tests. In the
            animation above, we have a test suite that consists of eight
            separate test files. This test suite is parallelized across four
            nodes. The algorithm will go through each test one by one and add it
            to the node that contains the smallest number of test files. This
            process will continue until all of the test files have been
            allocated.
          </p>
          <p>
            Though the stage one algorithm splits the files evenly amongst the
            parallel nodes, it does not necessarily represent the most efficient
            splitting of the test suite. This is because it can result in
            different nodes having longer total runtimes than other nodes, due
            to the possibility of certain test files taking longer to run than
            others.
          </p>
          <p>
            The image on the right shows that even though each node has the same
            number of test files, Node 1 takes much longer than Node 2, which is
            a problem because the test run is only as fast as the slowest node.
          </p>
          <img
            class="lazy"
            data-src="images/diagrams/split_by_file_count.png"
            alt="split by file count"
          />

          <h3 id="section-5-2">5.2 Stage 2: Allocate by Timing Data</h3>
          <p>
            The second stage of Conifer's test-allocation algorithm is where the
            test files are allocated based on test run timing data. After the
            initial run, Conifer persists metadata about each test file,
            including the time each test takes to run. On subsequent test runs,
            Conifer can use this test data to allocate the test files to
            minimize the difference in total test time between each parallel
            node.
          </p>
          <p>
            Beginning with the longest-running test file, the algorithm will go
            through each test file and add it to the node that contains the
            shortest estimated total test-run time. This process will continue
            until all of the test files have been allocated. We can see this
            process play out in the animation above.
          </p>
          <img
            class="lazy"
            data-src="images/diagrams/split_by_timing_data.png"
            alt="split by timing data"
          />
          <p>
            As we can see from the image above, this will result in nodes that
            take a similar amount of time to finish execution relative to the
            naive allocation.
          </p>
          <img class="lazy" data-src="images/diagrams/example-image.png" />

          <h3 id="section-5-3">5.3 Final Algorithm</h3>
          <p>
            On the initial test run, Conifer will allocate test files such that
            there is an even distribution of test files amongst the parallel
            nodes. On subsequent test runs, Conifer will utilize the timing data
            from the previous test run to allocate the tests among the nodes
            based on total test time.
          </p>
          <p>
            It is noteworthy that the naive algorithm will be responsible for
            the majority of the speed increase. This illustrates the power of
            parallelization, allowing the user to enjoy substantially reduced
            test suite runtime from the first run.
          </p>

          <!-- Section 6 -->
          <h2 id="section-6">6. Behind the Scenes: How Conifer Works</h2>

          <h3 id="section-6-1">6.1 Overview of Responsibilities</h3>
          <p>
            Before we discuss implementation details, it is helpful to define
            the various responsibilities that must be fulfilled to successfully
            parallelize an e2e test suite.
          </p>
          <p>
            At a high level, these responsibilities are summarized as follows:
          </p>
          <ol>
            <li>
              Preparing all of the tools and provisioning the necessary
              infrastructure to support parallel testing.
            </li>
            <li>Orchestrating/overseeing the testing process.</li>
            <li>Executing the testing code on a single node.</li>
            <li>Storing results of each test in persistent storage.</li>
            <li>
              Communicating the results of the test suite to the end-user in a
              useful manner.
            </li>
          </ol>

          <h3 id="section-6-2">6.2 Preparing Infrastructure Components</h3>
          <p>
            Before we can actually perform a parallelized test run, we need to
            prepare all of the components that will be used to build the
            parallelized testing infrastructure.
          </p>
          <p>We can divide these components into three main categories:</p>
          <ol>
            <li>
              A blueprint that specifies all of the files and dependencies that
              are required to run the user's application and its associated e2e
              tests. In other words, a blueprint for a single node.
            </li>
            <li>
              The actual physical infrastructure that will be used to run the
              parallel tests.
            </li>
            <li>
              Any support infrastructure that will be used to facilitate
              Conifer's functionalities, such as object storage and databases.
            </li>
          </ol>
          <p>How can we create such a blueprint?</p>

          <h3 id="section-6-3">
            6.3 Blueprint for a Single Node: Docker Image
          </h3>
          <p>
            Docker images are files that function as a set of instructions that
            are used to run a Docker container. Conifer uses a Docker image to
            specify a blueprint for a single node. The user can then use this
            image to spin up multiple Docker containers, each representing a
            single node running a different subset of the user's test suite.
          </p>
          <p>
            A Docker container is an instantiation of a Docker image, which
            bundles the application code with all the dependencies required to
            run the application. Running our nodes as Docker containers allows
            us to run our application and its associated tests on any computer
            without worrying about configuring the correct environment.
          </p>
          <p>
            By using the blueprint specified by a Docker image to spin up our
            parallel nodes, we dramatically simplify the deployment of the
            user's application on general-purpose cloud-computing
            infrastructure.
          </p>
          <p>
            So far, we have a blueprint for initializing a single node of our
            parallel testing infrastructure. However, this blueprint is not
            useful without access to physical computer infrastructure on which
            to run it.
          </p>

          <h3 id="section-6-4">6.4 Provisioning the Infrastructure</h3>
          <p>
            Conifer relies on the power of cloud infrastructure to supply the
            physical compute infrastructure that is needed to run the parallel
            nodes on which the user's application is tested. Like any tool that
            relies on cloud infrastructure, we must provision this
            infrastructure before it can be used.
          </p>
          <p>
            Provisioning the necessary infrastructure is accomplished through
            <a
              href="https://docs.aws.amazon.com/cdk/v2/guide/home.html"
              target="_blank"
              >AWS Cloud Development Kit</a
            >, or CDK. CDK acts as a wrapper for CloudFormation, providing a
            higher-level interface through which AWS cloud infrastructure can be
            specified. AWS's CDK was not the only option for accomplishing this
            task; other tools exist for provisioning infrastructure on the
            cloud. However, CDK possesses a few characteristics that gave it an
            edge over the competition (made it ideal for our use-case):
          </p>
          <ol>
            <li>
              Dramatically simpler than CloudFormation → Reduce complexity
            </li>
            <li>Can be written in an assortment of programming languages.</li>
          </ol>
          <p>
            Using CDK to provision our infrastructure allowed us to avoid the
            complexity of creating a CloudFormation template. Creating a
            CloudFormation template (a JSON or YAML file) on its own is a
            challenge since we would need to configure all the necessary
            networking resources like a VPC, subnets, and security groups.
            Furthermore, it does not provide any glue logic for
            service-to-service interactions. CDK abstracted away this complexity
            into what is essentially a library of functions that can be accessed
            in your choice of programming language, with support for languages
            including TypeScript, JavaScript, Python, and Golang.
          </p>
          <p>
            AWS uses the finished Cloudformation template to complete the
            provisioning process.
          </p>

          <h3 id="section-6-5">6.5 Managing the Test Orchestration Process</h3>
          <p>
            The next responsibility is the test orchestration process. The test
            orchestration process encompasses all of the actions that must be
            taken to execute a single test run. However, we cannot simply
            execute all of these actions as soon as the
            <code>conifer run</code> command is entered. Certain tasks must be
            triggered at certain points in the test run. Tasks also differ in
            the manner they are executed (synchronous vs asynchronous) and the
            interval at which they are run. To handle this complexity, we need
            to have a tool that will be responsible for overseeing this process.
          </p>
          <p>
            Within Conifer's architecture, the Command Line Interface, or CLI,
            is responsible for handling the test orchestration process.
          </p>
          <ol>
            <li>
              The CLI initiates the testing process in response to the
              <code>conifer run</code> command.
            </li>
            <li>
              While the test run is being executed, the CLI tracks the test
              suite's execution.
            </li>
            <li>
              After the test suite has finished execution, the CLI triggers the
              recalculation of the test groupings.
            </li>
          </ol>
          <p>
            Let's break down each of these responsibilities, beginning with the
            process of initiating a test run.
          </p>
          <h4 id="section-6-5-1">Initiating a Test Run</h4>
          <h5 id="section-6-5-1-1">Requirements</h5>
          <p>
            What processes need to occur to initiate the execution of a single
            run of the user's test suite? We can easily identify a few crucial
            steps:
          </p>
          <ol>
            <li>
              We must spin up the nodes that the test suite is going to be run
              on.
            </li>
            <li>
              We must specify the specific test files that are going to be
              executed on a specific node.
            </li>
            <li>
              We must be able to specify the specific test run for which a test
              file is executed.
            </li>
            <li>
              We must save some sort of reference to each node for tracking
              purposes.
            </li>
          </ol>
          <p>
            As mentioned in the previous section, the Conifer CLI is responsible
            for managing the test orchestration process. Let's examine how the
            CLI fulfills the above requirements.
          </p>
          <h5 id="section-6-5-1-2">Implementation</h5>
          <p>
            The CLI uses the
            <a href="https://aws.amazon.com/sdk-for-javascript/" target="_blank"
              >AWS Software Development Kit</a
            >
            (SDK) to initiate a single test run.
          </p>
          <p>
            The SDK triggers the creation of ECS Tasks, which are instantiations
            of ECS Task Definitions. ECS Task Definitions specify container
            configurations such as CPU/memory allocation, which image to use,
            and which ports to expose. We can use the skeleton specified by an
            ECS Task Definition to instantiate the nodes of our parallelized
            test execution infrastructure.
          </p>
          <p>
            When initiating a task, we have the option of specifying container
            overrides. We take advantage of this capability to supply values
            that each node requires to run by specifying them as environment
            variables. The following environment variables are specified for
            each node:
          </p>
          <ol>
            <li>
              A file globbing pattern that dictates which test files will be
              executed on the node.
            </li>
            <li>
              A unique identifier for the specific test run that the node is
              associated with. This identifier will be used to organize test
              artifacts and metadata.
            </li>
          </ol>
          <p>
            Each task spins up a container using the image we pushed to ECR.
            Within each container, environment variables specify the test run
            and the test files that will be executed.
          </p>
          <p>
            Each node remains associated with the task instance that it was spun
            up with. AWS assigns each of these tasks Amazon Resource Names, or
            ARNs. ARNs are unique IDs that can be used to identify specific AWS
            resources. Upon the conclusion of the test run initiation process,
            the Task ARNs will be persisted in the Conifer-Config file. They
            will be used to track the status of the tasks.
          </p>
          <h4 id="section-6-5-2">Monitoring Test Suite Execution</h4>
          <h5 id="section-6-5-2-1">Requirements</h5>
          <p>
            At this point, we have successfully initiated e2e testing of the
            user's application, and the user's test suite is executing on the
            parallel nodes of Conifer's testing infrastructure.
          </p>
          <p>
            Certain functionalities need to be triggered at certain points as
            the execution of the test suite progresses. For example:
          </p>
          <ol>
            <li>
              While the test suite is executing, we want to query the persistent
              store for updates on the status of individual test files, in order
              to keep the user up-to-date.
            </li>
            <li>
              After the test suite has finished executing, we want to trigger
              the recalculation of the test groupings.
            </li>
          </ol>
          <p>
            In order to ensure that the necessary processes are run at the
            correct time, we need to be able to monitor the status of the nodes
            that make up our parallelized testing infrastructure. Specifically,
            we need to track each node while it is running and ensure that it
            executes its responsibilities and shuts down without incident.
          </p>
          <h5 id="section-6-5-2-2">Implementation</h5>
          <p>
            The CLI monitors each node using functions supplied by the AWS SDK.
            Recall that each ECS task is assigned a unique identifier in the
            form of an ARN, and that these ARNs were persisted during test run
            initiation. By supplying these identifiers, the SDK's
            <em>describe</em>
            functions can now be used to query the status of each node.
          </p>
          <p>
            The CLI will poll AWS for the status of each node at a certain
            interval for the duration of the test run. This process will
            continue until each node returns a status of complete, upon which
            the test run will be marked as complete.
          </p>

          <h3 id="section-6-6">
            6.6 Executing the Test Suite: Within a Single Node
          </h3>
          <h4 id="section-6-6-1">Requirements</h4>
          <p>
            As discussed earlier, parallelized execution of the user's entire
            test suite is accomplished by initializing N nodes, with each node
            running a subset of the entire test suite as specified during the
            initiation procedure.
          </p>
          <p>
            Now, let's zoom in on a single node within this parallelized testing
            infrastructure. Each node must perform certain actions in order to
            successfully execute its portion of the test suite. At a high level,
            these actions include:
          </p>
          <ol>
            <li>Initiating the necessary background processes.</li>
            <li>
              Launching the user's application and ensuring that it is running.
            </li>
            <li>
              Starting Cypress and instructing it to execute the necessary
              tests.
            </li>
          </ol>
          <h4 id="section-6-6-2">Implementation</h4>
          <p>
            Conifer uses a simple shell script to control the flow of the test
            execution process within each node. This shell script is triggered
            at the creation of the node, and executes the following processes
            sequentially:
          </p>
          <ol>
            <li>
              Launches a continuous file-watcher process in the background. This
              specific process will be discussed in detail in the coming
              section.
            </li>
            <li>
              Starts the user's application using the commands specified during
              the Conifer initialization process.
            </li>
            <li>
              Waits for the application to finish starting up by listening to
              the necessary port, as indicated by the user during the Conifer
              initialization process.
            </li>
            <li>
              Initiates testing by launching the Cypress framework with flags
              that indicate which tests to run, using environment variables that
              were specified for the node.
            </li>
          </ol>
          <p>
            Running this script will execute a subset of the complete test suite
            on a single node. Taken collectively, this will result in the entire
            test suite being executed amongst the constituent nodes of Conifer's
            parallelized testing infrastructure.
          </p>

          <h3 id="section-6-7">6.7 Persisting Test Results</h3>
          <h4 id="section-6-7-1">Requirements</h4>
          <p>
            At this point, we have managed to speed up execution of the user's
            test suite by splitting it up into smaller parts running it
            in-parallel across the nodes of Conifer's parallelized testing
            infrastructure. After a test is executed, we need to store its
            results in some form of persistent storage. This storage should be
            external to test execution infrastructure to enable us to access the
            results of tests run nodes that may no longer be active.
          </p>
          <p>
            The process of persisting the test results can be broken down into
            two main steps:
          </p>
          <ol>
            <li>Determining when results for a single test are available.</li>
            <li>
              Saving the results for a single test to storage outside of the
              testing infrastructure.
            </li>
          </ol>
          <h4 id="section-6-7-2">Cypress Test Artifacts</h4>
          <p>
            Before examining how a solution to this requirement may be
            implemented, let's discuss how Cypress stores test results. Cypress
            can be configured to generate certain “test artifacts'' upon the
            completion of a single test file. Cypress stores various artifacts
            in different file formats, including JSON, MP4, and PNG. Together,
            these artifacts function to communicate the results of the test,
            including test metadata, recordings, and screenshots of any points
            of failure.
          </p>
          <p>
            Because Cypress test artifacts take the form of physical files,
            storing the results of a Cypress test is as simple as exporting the
            files and persisting them in some form of external storage.
          </p>
          <h4 id="section-6-7-3">Implementation</h4>
          <p>
            Recall that a file-watcher is run in the background of each node
            before the Cypress testing framework is started. The file-watcher
            detects when a test artifact has been generated by watching for
            changes in the standard directories where Cypress test artifacts are
            saved. When a new artifact is detected, the file-watcher uploads it
            to the appropriate directory in the Conifer S3 bucket.
          </p>
          <img
            class="lazy"
            data-src="images/diagrams/file_watcher.png"
            height="400px"
          />
          <p>
            Additionally, the file-watcher parses some of the artifacts for
            select metadata to save to DynamoDB. This includes high-level
            information about each individual test, such as its status and
            duration. This metadata will later be used to support real-time
            monitoring of a test run's progression.
          </p>

          <h3 id="section-6-8">6.8 Communicating Test Results to the User</h3>
          <h4 id="section-6-8-1">Requirements</h4>
          <p>
            At this point, let's discuss how we might communicate the test
            results back to the end-user. A general process for returning
            results to the user can be broken down into three main steps:
          </p>
          <ol>
            <li>
              We need to retrieve the test results from where they are stored.
            </li>
            <li>
              We need to apply some form of processing to transform the data
              into a useful format for display.
            </li>
            <li>Finally, we need to display via some GUI.</li>
          </ol>
          <p>
            Let's consider the temporal aspect of communicating the test results
            to the user. Before attempting an implementation, we need to decide
            whether we want to support displaying the results in real-time
            versus at the end of execution.
          </p>
          <h4 id="section-6-8-2">Implementation</h4>
          <p>
            We decided that it was important to support some level of real-time
            streaming of the test results. The user would receive a high-level
            view of the results of the test-run in real-time, as well as a
            detailed report following the conclusion of testing. This
            functionality was implemented with two separate infrastructures:
          </p>
          <ol>
            <li>
              Live dashboard - High-level overview of the test run, communicated
              in real-time.
            </li>
            <li>
              HTML report - A detailed report after the test run is complete.
            </li>
          </ol>
          <h5 id="section-6-8-2-1">Live Dashboard</h5>
          <p>
            Real-time communication of test results is handled by the live
            dashboard. The live dashboard utilizes the data persisted by the
            file-watcher to keep the user up-to-date on the status of the test
            run. It consists of an Express back-end server and a React front-end
            web application. Recall that the CLI is responsible for managing the
            test orchestration process, including monitoring the progression of
            a test run. As part of this process, the CLI polls Dynamodb for
            test-status updates, and sends webhooks containing these updates to
            the dashboard application. Upon receipt, the updates are
            communicated to the user via the React application.
          </p>
          <p>
            The live dashboard enables real-time monitoring of the progression
            of a test run, allowing the user to track:
          </p>
          <ol>
            <li>The status of each individual test within the test suite.</li>
            <li>The duration of each test.</li>
          </ol>
          <p>
            The user dashboard also provides links to download individual test
            artifacts from AWS S3 as they become available.
          </p>
          <h5 id="section-6-8-2-2">HTML Report</h5>
          <p>
            Conifer generates an HTML report after each test run and saves it to
            the user's project directory. This report is much more detailed than
            the data provided by the live dashboard, and represents a complete
            accounting of the test run-it contains all of the information the
            user would have had access to had they run the test-suite locally.
          </p>
          <p>
            The report generation process is initiated when the CLI detects that
            all test execution nodes have powered down. This indicates that the
            test run is complete. The process of generating the HTML report can
            be divided into two main steps:
          </p>
          <ol>
            <li>
              The relevant test artifacts that were produced in the test run are
              downloaded to the user's computer.
            </li>
            <li>
              Each artifact is parsed and aggregated into a single data
              structure.
            </li>
            <li>
              An HTML report is generated using the aggregated data, and is then
              saved to the user's project directory.
            </li>
          </ol>
          <p>
            Together, the live dashboard and HTML report function as a versatile
            and user-friendly mechanism for monitoring test execution and making
            sense of test results.
          </p>

          <h3 id="section-6-9">6.9 Final Architecture</h3>
          <img
            class="lazy"
            data-src="images/diagrams/conifer_full_architecture.png"
            alt="Conifer's full architecture"
          />
          <p>The above image illustrates Conifer's final architecture.</p>
          <ol>
            <li>
              Conifer generates the Docker image and provisions the necessary
              AWS infrastructure.
            </li>
            <li>
              The CLI initiates a test run and tracks each task for completion.
            </li>
            <li>
              While a subset of tests are run within each task, the test
              artifacts/metadata are sent to S3 and DynamoDB.
            </li>
            <li>
              Finally, the artifacts and metadata are retrieved from S3 and
              DynamoDB and presented to the user via the HTML report and live
              dashboard, respectively.
            </li>
          </ol>

          <!-- Section 7 -->
          <h2 id="section-7">7. Implementation Challenges</h2>

          <h3 id="section-7-1">7.1 Going Serverless</h3>
          <h4 id="section-7-1-1">Initial Design: AWS Lambda</h4>
          <p>
            After the consolidated Docker image has been built and sent to ECR,
            how can we run the tests in a parallelized manner on the cloud?
          </p>
          <p>
            Our first thought was to use Lambda functions. Lambda is an
            event-driven compute service that lets you run code without needing
            to provision or manage any resources. We had envisioned utilizing
            Lambda functions to parallelize the test execution. Each Lambda
            function could execute each test file in the test suite
            asynchronously. The concept would be to invoke N number of Lambda
            functions, where each function runs one test file in the complete
            test suite.
          </p>
          <img
            class="lazy"
            data-src="images/diagrams/lambda_initial_design.png"
            alt="lambda architecture"
          />
          <p>
            Lambda has many characteristics that make it uniquely suitable for
            our use case:
          </p>
          <ol>
            <li>
              It possesses the capacity for infinite parallelization, so it is
              highly scalable.
            </li>
            <li>
              It represents a fully-managed solution, so we do not need to
              manage the deployment of AWS resources.
            </li>
            <li>
              It is a proven solution. This approach has successfully
              parallelized end-to-end testing on Selenium, another popular
              testing framework.
            </li>
          </ol>
          <p>
            Aside from these upsides, we considered a few possible drawbacks:
          </p>
          <ol>
            <li>
              The container size limit is an issue. This used to be a bigger
              problem when the size limit was 512 MB, but recently it was
              <a
                href="https://aws.amazon.com/about-aws/whats-new/2020/12/aws-lambda-supports-10gb-memory-6-vcpu-cores-lambda-functions/"
                target="_blank"
                >increased to 10 GB</a
              >, so it is suitable for most applications. In any case, we
              thought it was sufficient to support applications under the 10 GB
              limit.
            </li>
            <li>
              Function timeout is
              <a
                href="https://aws.amazon.com/about-aws/whats-new/2018/10/aws-lambda-supports-functions-that-can-run-up-to-15-minutes/"
                target="_blank"
                >only 15 minutes</a
              >. In theory, it is an issue, but because there is potential to
              parallelize infinitely, it is improbable that a single Cypress
              test file would take more than 15 minutes.
            </li>
            <li>
              Cold start time can vary based on what the Lambda function is
              running. It could be an issue, but we must validate it with
              real-world data.
            </li>
          </ol>
          <h4 id="section-7-1-2">Issues with Lambda</h4>
          <p>
            During implementation with Lambda, we encountered an issue relating
            to a low-level display driver dependency for Cypress, and it had
            conflicts with running on Lambda. Upon further research, this issue
            appeared unsolvable as there is still an
            <a
              href="https://github.com/cypress-io/cypress/issues/1232"
              target="_blank"
              >open issue</a
            >
            on Github directly related to using Lambda with Cypress, dating back
            to 2018.
          </p>

          <img
            class="lazy"
            data-src="images/diagrams/lambda-error.png"
            alt="lambda error"
          />

          <p>
            We also explored a handful of workarounds that attempted to bypass
            this problem. These were typically very complex and were always
            implemented to support the testing of a specific application. These
            workarounds were not intended to be used as a part of a general
            purpose testing infrastructure. Therefore, they were not suitable
            for use with Conifer.
          </p>
          <h4 id="section-7-1-3">
            An Alternative: Elastic Container Service (ECS)
          </h4>
          <p>
            Since we appeared to have reached the end of the road with Lambda,
            ECS had a few characteristics that made it desirable for our use
            case. Being a container orchestration service for Docker images, it
            is able to run our nodes. Additionally, it can scale easily in a
            manner that will allow us to parallelize the execution of our test
            suite sufficiently and can fulfill the same responsibilities that we
            had originally envisioned using Lambdas.
          </p>
          <p>
            Unlike Lambdas, which are entirely serverless, ECS offers two launch
            types from which we can use to run our nodes.
          </p>
          <ol>
            <li>
              ECS with EC2: A self-managed solution using an EC2 instance as a
              task runner.
            </li>
            <li>ECS with Fargate: A serverless, fully-managed solution.</li>
          </ol>
          <p>
            We took the bottom-up approach by trying to get Cypress to work on
            an EC2 instance. Initial development began with EC2 as a task
            runner, with an immediate goal of ensuring that nodes can run the
            tests and with the intent to verify that the same problem with
            Lambda did not apply. Using EC2 as the task runner made it possible
            to take advantage of the relative ease of debugging and
            troubleshooting in a self-managed solution for the initial
            application development.
          </p>
          <p>
            Ultimately, we decided to stay with EC2 as our task runner. In
            addition to simplifying the development process, using EC2 as the
            task runner achieved the substantial speed gains that Conifer aimed
            to provide for e2e testing. Implementation with a fully managed
            solution via Fargate was deferred as a future optimization.
          </p>

          <h3 id="section-7-2">7.2 Sending Tests Results to the User</h3>
          <p>
            With the tests now being run within a distributed environment on the
            cloud through EC2, let us look at the results of these test runs.
            But how can we do that?
          </p>
          <p>
            Normally, the user could view their test results in real-time
            through their terminal. Since Conifer executes the tests on the
            cloud, they lose this feature.
          </p>
          <p>
            What's the point of testing if you cannot see the results? Is there
            another way to view results besides the terminal output?
          </p>
          <p>
            One way is to create a test report for the user to see these results
            through an HTML report after the test run is complete. Although,
            this would not let them see the tests in real-time as they are
            executed. This can be achieved natively through Cypress with its
            built-in reporters. Unlike viewing the test results through the
            terminal's output, these reports can be retrieved from each node and
            sent to the user.
          </p>
          <p>
            There is one minor problem when the user receives these reports. The
            reports are generated per each test file, meaning that the user has
            to go through hundreds of reports to see their test results.
          </p>
          <p>
            We managed to solve this problem easily by using a custom reporter
            plugin called mochawesome-report-generator (marge) which can
            aggregate all the tests and generate a final HTML report.
          </p>
          <p>
            However, before we can aggregate the individual test results, we
            need them in a single location.
          </p>

          <img
            class="lazy"
            data-src="images/diagrams/current-situation.png"
            alt="current situation"
          />

          <p>
            The above image illustrates the current situation after our test
            suite has finished execution. The test results/artifacts were
            produced for each test, but they reside within the node where the
            specific test file was executed. Therefore, we don't have access to
            them and cannot use them to generate the report for the end-user.
          </p>
          <p>
            In order to send any results to the user, we need first to retrieve
            the test results from each node and place them in one centralized
            location.
          </p>
          <p>
            The easiest approach would be to defer uploading the test artifacts
            until after all of the tests within a single node have finished
            running. The conclusion of test execution on a node implies that the
            Cypress test runner has finished running, and thus, that all of the
            artifacts have been generated. Running a script after this to upload
            the test artifacts would be a trivial process.
          </p>
          <h4 id="section-7-2-1">Real-Time Results</h4>
          <p>
            But this is not good enough. We want Conifer to be able to
            communicate the test results to the user in real-time, which is
            present when running a Cypress test suite locally. Accomplishing
            this requires us to retrieve the test results from each node in
            real-time as those test results are generated.
          </p>
          <p>We arrived at two main approaches:</p>
          <ul>
            <li>
              Synchronous: We can attempt to insert the desired functionality
              directly into the test execution process, so the test results are
              uploaded immediately after a test file runs but before the next
              test file run begins.
            </li>
            <li>
              Asynchronous: We can create a separate process solely responsible
              for uploading the test results as they are created.
            </li>
          </ul>
          <h5 id="section-7-2-1-1">Synchronous Approach</h5>
          <p>
            The first approach would be to direct Cypress to synchronously
            upload the test artifacts for a single test file immediately after
            that file finishes running. Within the cypress-config file, Cypress
            allows us to extend the internal behavior of Cypress with code
            blocks that can be executed at certain events within the testing
            process, including subsequent to the completion of an individual
            test file's execution.
          </p>
          <p>
            This approach is complex due to the potential for existing code in
            the user's cypress-config file, some of which may be critical for
            supporting the proper execution of their test suite (e.g., seeding a
            database, fetching database data, etc.). Thus, the necessary code
            would need to be stitched into a preexisting cypress-config file in
            one of two approaches:
          </p>
          <ul>
            <li>Require the user to add the necessary code themselves.</li>
            <li>
              Inject the necessary code into the user's cypress-config file.
            </li>
          </ul>
          <p>
            Upon further investigation and given the config file's complexity
            and importance in successfully executing the user's test suite, we
            deemed the second approach unviable and too risky.
          </p>
          <h5 id="section-7-2-1-2">Asynchronous Approach</h5>
          <p>
            This approach would enable the asynchronous streaming of the test
            artifacts by implementing a file-watcher. This program would be
            separate from Cypress and run asynchronously in the background while
            the Cypress tests are executed.
          </p>
          <p>
            In order to function correctly, the file-watcher would need to
            detect when a test artifact has been created and fully written (as
            indicated by it no longer changing). Once these conditions are
            satisfied, the file-watcher would initiate uploading the specific
            test artifact to persistent storage.
          </p>
          <p>
            This approach would require no additional work from the user, but it
            is more complex and constitutes an additional point of failure in
            the testing infrastructure.
          </p>
          <h5 id="section-7-2-1-3">Decision: File-Watcher</h5>
          <p>
            We decided that the implementation of real-time streaming of testing
            artifacts would be best achieved through the use of the asynchronous
            file-watcher.
          </p>
          <p>
            Both of these approaches achieved the necessary functionality. The
            first approach would be undesirable because it burdens the end-user
            with needing to stitch the configuration files together. This is
            particularly true when the user may not even be familiar with the
            configuration themselves, making the synchronous approach a
            non-starter.
          </p>
          <p>
            Although the file-watcher approach was more of a technical
            challenge, it supports the necessary functionality without requiring
            additional work from the user.
          </p>
          <img class="lazy" data-src="images/diagrams/example-image.png" />

          <!-- Section 8 -->
          <h2 id="section-8">8. Future Work</h2>
          <p>
            Conifer is designed to address the current use case we envisioned.
            However, there are several features we would like to add in the
            future:
          </p>

          <h3 id="section-8-1">8.1 Dynamic Allocation of Tests</h3>
          <img
            class="lazy"
            data-src="images/diagrams/dynamic_allocation.gif"
            alt="dynamic allocation"
          />

          <p>
            In the future, our team would like to investigate other test
            allocation algorithms that may be useful to users with certain use
            cases. One such algorithm is through the dynamic allocation of
            tests. The animation above illustrates the approach. Rather than
            calculate test groupings before initiating a test run, this approach
            would dynamically allocate tests by utilizing a queue of sorts to
            feed tests to the nodes as they become available. This approach may
            prove useful in situations where accurate or up-to-date timing data
            is unavailable such as during the first run and in frequently or
            rapidly changing test suites
          </p>

          <h3 id="section-8-2">8.2 Additional Features</h3>
          <p>
            AWS Fargate as task runner - There is potential for a Lambda-like
            parallelization if the kinks can be worked out. We would be able to
            realize the benefits of a fully-managed, serverless solution.
          </p>
          <p>
            The remaining points are some features that will potentially
            increase the efficiency of testing for developers when testing
            locally:
          </p>

          <ul>
            <li>
              Fail fast - The option to stop test execution as soon as the first
              failing test result is found.
            </li>
            <li>
              Flaky test detection - The developer can detect, flag, and track
              flaky tests from the Cypress test runs.
            </li>
            <li>
              Live dashboard analytics - Give developers a richer experience on
              their test results.
            </li>
          </ul>
        </div>
      </div>
    </div>

    <div id="presentation" class="main-section">
      <div class="bg-white">
        <h2>Presentation</h2>
        <iframe
          src="https://www.youtube-nocookie.com/embed/r5_M8aUN9oY"
          title="Conifer Presentation"
          frameborder="0"
          allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
          allowfullscreen
        ></iframe>
      </div>
    </div>

    <div id="our-team" class="main-section">
      <div>
        <div>
          <div>
            <h2>Meet our team</h2>
            <p class="text-xl text-gray-300">
              We are currently looking for opportunities. If you liked what you
              saw and want to talk more, please reach out!
            </p>
          </div>
          <ul class="people">
            <li class="profile">
              <img
                class="mx-auto h-40 w-40 rounded-full xl:w-56 xl:h-56 lazy"
                data-src="images/team/aj.jpg"
                alt=""
              />
              <div>
                <div>
                  <h3>Ahmad Jiha</h3>
                  <p>Bay Area, CA</p>
                </div>

                <ul class="social">
                  <li>
                    <a href="mailto:ahmad.j.jiha@gmail.com" target="_blank"
                      ><i class="fas fa-envelope"></i
                    ></a>
                  </li>
                  <li>
                    <a
                      href="https://www.linkedin.com/in/ahmad-jiha/"
                      target="_blank"
                      ><i class="fab fa-linkedin"></i
                    ></a>
                  </li>
                  <li>
                    <a href="https://github.com/ahmadjiha" target="_blank"
                      ><i class="fab fa-github"></i
                    ></a>
                  </li>
                  <li>
                    <a href="https://github.com/ahmadjiha" target="_blank"
                      ><i class="fas fa-globe"></i
                    ></a>
                  </li>
                </ul>
              </div>
            </li>

            <li class="profile">
              <img
                class="mx-auto h-40 w-40 rounded-full xl:w-56 xl:h-56 lazy"
                data-src="images/team/sh.jpg"
                alt=""
              />
              <div>
                <div>
                  <h3>Sam Harreschou</h3>
                  <p>Los Angeles, CA</p>
                </div>

                <ul class="social">
                  <li>
                    <a href="mailto:sam.inspect@gmail.com" target="_blank"
                      ><i class="fas fa-envelope"></i
                    ></a>
                  </li>
                  <li>
                    <a
                      href="https://www.linkedin.com/in/samuel-harr/"
                      target="_blank"
                      ><i class="fab fa-linkedin"></i
                    ></a>
                  </li>
                  <li>
                    <a href="https://github.com/samh19826" target="_blank"
                      ><i class="fab fa-github"></i
                    ></a>
                  </li>
                  <li>
                    <a href="https://github.com/ahmadjiha" target="_blank"
                      ><i class="fas fa-globe"></i
                    ></a>
                  </li>
                </ul>
              </div>
            </li>

            <li class="profile">
              <img
                class="mx-auto h-40 w-40 rounded-full xl:w-56 xl:h-56 lazy"
                data-src="images/team/as.jpg"
                alt=""
              />
              <div>
                <div>
                  <h3>Ainaa Sakinah</h3>
                  <p>Tokyo, Japan</p>
                </div>

                <ul class="social">
                  <li>
                    <a href="mailto:ainaasakinah@gmail.com" target="_blank"
                      ><i class="fas fa-envelope"></i
                    ></a>
                  </li>
                  <li>
                    <a
                      href="https://www.linkedin.com/in/ainaasakinah/"
                      target="_blank"
                      ><i class="fab fa-linkedin"></i
                    ></a>
                  </li>
                  <li>
                    <a href="https://github.com/anotherainaa" target="_blank"
                      ><i class="fab fa-github"></i
                    ></a>
                  </li>
                  <li>
                    <a href="https://github.com/anotherainaa" target="_blank"
                      ><i class="fas fa-globe"></i
                    ></a>
                  </li>
                </ul>
              </div>
            </li>

            <li class="profile">
              <img
                class="mx-auto h-40 w-40 rounded-full xl:w-56 xl:h-56 lazy"
                data-src="images/team/lt.jpg"
                alt=""
              />
              <div>
                <div>
                  <h3>Lawrence Tam</h3>
                  <p>Bay Area, CA</p>
                </div>

                <ul class="social">
                  <li>
                    <a href="mailto:lawrenceatam@gmail.com" target="_blank"
                      ><i class="fas fa-envelope"></i
                    ></a>
                  </li>
                  <li>
                    <a
                      href="https://www.linkedin.com/in/lawrenceatam/"
                      target="_blank"
                      ><i class="fab fa-linkedin"></i
                    ></a>
                  </li>
                  <li>
                    <a href="https://github.com/lt-z" target="_blank"
                      ><i class="fab fa-github"></i
                    ></a>
                  </li>
                  <li>
                    <a href="https://github.com/lt-z" target="_blank"
                      ><i class="fas fa-globe"></i
                    ></a>
                  </li>
                </ul>
              </div>
            </li>
          </ul>
        </div>
      </div>
    </div>

    <script src="javascripts/script.js"></script>
  </body>
</html>
